# CarbonData基础特性

1. 多维数据聚集：在入库时对数据按多个维度进行重新组织，使数据在“多维空间上更内聚”，在存储上获得更好的压缩率，在计算上获得更好的数据过滤效率。
2. 带索引的列存文件结构：首先，CarbonData为多类场景设计了多个级别的索引，并融入了一些搜索的特性，有跨文件的多维索引，文件内的多维索引，每列的minmax索引，以及列内的倒排索引等。其次，为了适应HDFS的存储特点，CarbonData的索引和数据文件存放在一起，一部分索引本身就是数据，另一部分索引存放在文件的元数据结构中，他们都能随HDFS提供本地化的访问能力。
3. 列组：整体上，CarbonData是一种列存结构，但相对于行存来说，列存结构在应对明细数据查询时会有数据还原代价高的问题，所以为了提升明显数据查询性能，CarbonData支持列组的存储方式，用户可以把某些不常作为过滤条件但又需要作为结果集返回的字段作为列组来存储，经过CarbonData编码后会将这些字段使用行存的方式来存储以提升查询性能。
4. 数据类型：目前CarbonData支持所有数据库的常用基本类型，以及Array，Struct复杂嵌套类型。同时社区也有人提出支持Map数据类型，我们计划未来添加Map数据类型。
5. 压缩：目前CarbonData支持Snappy压缩，压缩是针对每列分别进行的，因为列存的特点使得压缩非常高效。数据压缩率基于应用场景不同一般在2到8之间。
6. Hadoop集成：通过支持InputFormat/OutputFormat接口，CarbonData可以利用Hadoop的分布式优点，也能在所有以Hadoop为基础的生态系统中使用。
# CarbonData高级特性

1. 可计算的编码方式：除了常见的Delta，RLE，Dictionary，BitPacking等编码方式外，CarbonData还支持将多列进行联合编码，以及应用了全局字典编码来实现免解码的计算，计算框架可以直接使用经过编码的数据来做聚合，排序等计算，这对需要大量shuffle的查询来说性能提升非常明显。
2. 与计算引擎联合优化：为了高效利用CarbonData经过优化后的数据组织，CarbonData提供了有针对性的优化策略，目前CarbonData社区首先做了和Spark的深度集成，其中基于SparkSQL框架增强了过滤下压，延迟物化，增量入库等特性，同时支持所有DataFrame API。相信未来通过社区的努力，会有更多的计算框架与CarbonData集成，发挥数据组织的价值。
目前这些特性都已经合入Apache CarbonData主干，欢迎大家使用。


Apache CarbonData主要特点包括：

1. 列式存储：高效的列式数据组织，区别于行存，可以实现列裁剪和过滤下压，使OLAP查询性能更高。同时，CarbonData针对明细数据查询实现了深度优化，在需要返回所有列的场景下性能优于其他列存方案。

2. 丰富的索引支持：支持全局多维索引、文件索引、Min/Max、倒排索引等多种索引技术，从表级，文件级，列级等多个层级逐级快速定位数据，避免SQL-on-Hadoop引擎常见的“暴力扫描“，从而大幅提升性能，实现十年数据秒级响应， 三百维字段任意组合查询。

3. 全局字典编码：除了常见的Delta、RLE、BitPacking等编码外，CarbonData应用了全局字典编码来实现免解码的计算，计算框架可以直接使用经过编码的数据来做聚合，排序等计算，这对需要做跨节点数据交换的业务来说性能提升非常明显。

4. 自适应类型转换：CarbonData针对分析型应用中大量使用的数值类型（Double/Decimal/Numeric/BigInt）实现存储内数据类型转换，配合列式数据压缩，使得压缩非常高效，数据压缩率基于应用场景不同一般压缩比在2到8之间。

* 标准SQL和API：在SparkSQL基础上，支持标准SQL99/2003；支持数据批量更新、删除，适用于OLAP场景下数据的周期性刷新，例如拉链表更新、维表数据同步。提供JDBC/ODBC连接，支持与BI工具无缝对接；兼容Spark DataFrame/DataSet，支持复杂分析应用。

* 数据生态集成：支持与Hadoop、Spark等大数据生态系统集成，支持和商业BI工具无缝对接。既满足传统数仓、数据集市、BI应用要求，也提供大数据生态丰富多样的API支持，覆盖从GB级到EB级应用。
# Dynamic Resource Allocation

## Sarpk Application Config
```
spark.dynamicAllocation.enabled=true
spark.shuffle.service.enabled=true
spark.dynamicAllocation.initialExecutors=2
spark.dynamicAllocation.maxExecutors=20
spark.dynamicAllocation.minExecutors=2
```

```
unset HIVE_HOME
unset HIVE_CONF_DIR
export HIVE_SERVER2_THRIFT_PORT=10001
export HIVE_SERVER2_THRIFT_BIND_HOST=0.0.0.0
sbin/start-thriftserver.sh --conf spark.sql.hive.thriftServer.singleSession=true \
--conf spark.hadoop.yarn.timeline-service.enabled=false \
--conf spark.sql.hive.convertMetastoreOrc=false \
--conf spark.dynamicAllocation.enabled=true \
--conf spark.shuffle.service.enabled=true \
--conf spark.dynamicAllocation.initialExecutors=2 \
--conf spark.dynamicAllocation.maxExecutors=20 \
--conf spark.dynamicAllocation.minExecutors=2 \
--master yarn \
--executor-cores 6 \
--queue default \
--conf spark.yarn.executor.memoryOverhead=2G \
--executor-memory 20G \
--driver-memory 20G \
--files hdfs://csdncluster/apps/spark/log4j.properties
```

## Yarn Config

1. add $SPARK_HOME/yarn/spark-<version>-yarn-shuffle.jar to classpath of all NodeManagers in your cluster.

2. In the yarn-site.xml on each node, add spark_shuffle to yarn.nodemanager.aux-services, then set yarn.nodemanager.aux-services.spark_shuffle.class to org.apache.spark.network.yarn.YarnShuffleService.


3. Increase NodeManager's heap size by setting YARN_HEAPSIZE (1000 by default) in etc/hadoop/yarn-env.sh to avoid garbage collection issues during shuffle.

4. Restart all NodeManagers in your cluster.
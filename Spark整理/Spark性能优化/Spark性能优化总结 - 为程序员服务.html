<!DOCTYPE html>
<!-- saved from url=(0037)http://ju.outofmemory.cn/entry/237300 -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta name="viewport" content="initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0, user-scalable=no, width=device-width">
    <meta content="telephone=no" name="format-detection">
    <meta name="apple-mobile-web-app-capable">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta http-equiv="Cache-Control" content="no-transform">
    <meta http-equiv="Cache-Control" content="no-siteapp">
    <meta name="description" content="近期优化了一个 spark流量统计的程序 ，此程序跑5分钟小数据量日志不到5分钟，但相同的程序跑一天大数据量日志各种失败。经优化，使用160 vcores
+ 480G memory，一天的日志可在2.5小时内跑完，下面对一些优化的思路方法进行梳理。 优化的目标 保证大数据量下任务运行成功 降低资源消耗
提高计算性能 三个目标优先

">
    <meta name="keywords" content="spark,{memory},gc,{tuning},{direct} Spark性能优化总结">
    <title>Spark性能优化总结 - 为程序员服务</title>
    <link href="./Spark性能优化总结 - 为程序员服务_files/15.24.css" type="text/css" rel="stylesheet">
    
    <link rel="shortcut icon" href="http://outofmemory.cn/favicon.ico" type="image/x-icon">
    
</head>
<body>

<header class="head">
<div class="head-left">
    <div class="logo"><a href="http://outofmemory.cn/">OutOfMemory.CN</a></div>
    <div class="beta"><sup>β</sup></div>
    <div class="nav">
        <ul id="headNav">
            <li class="current"><a href="http://ju.outofmemory.cn/" title="聚客：编程技术网站牛人牛博聚集地">聚客</a></li>
            <li><a href="http://outofmemory.cn/code-snippet/" title="代码：分享代码 分享经验">代码</a></li>
            <li><a href="http://j.outofmemory.cn/" title="技术专栏，精华">专栏</a></li>
            <li><a href="http://outofmemory.cn/tutorial/" title="简单易学的技术教程">教程</a></li>
            <li style="width:65px"><a href="http://maven.outofmemory.cn/" title="Maven信息库速查">Maven</a></li>
            <li><a href="http://outofmemory.cn/github/" title="Github上的中国开源人">Gitter</a></li>
            <li><a href="http://outofmemory.cn/tag/" title="标签">标签</a></li>
        </ul>
    </div>
</div>
<div class="head-right">
<div class="userStatus"><a class="signin" target="_self" href="http://outofmemory.cn/user/login"><i></i><b>登录</b></a><a class="signup" target="_self" href="http://outofmemory.cn/user/register"><i></i><b>注册</b></a></div>
</div>
</header>


<div class="wrap">
<div class="content"><h1>Spark性能优化总结</h1>
<div class="meta">
    <a href="http://ju.outofmemory.cn/feed/2894/" title="Tao&#39;s Blog"><i class="ico man"></i>Tao's Blog</a>
    <time><i class="ico date"></i>2015-11-22</time>
    <span class="pv"><b>17</b> 阅读</span>
</div>
<div class="tags">
<a class="tag" href="http://ju.outofmemory.cn/tag/spark/">spark</a>

<a class="tag" href="http://ju.outofmemory.cn/tag/gc/">gc</a>

</div>

<script src="./Spark性能优化总结 - 为程序员服务_files/hm.js"></script><script async="" src="./Spark性能优化总结 - 为程序员服务_files/analytics.js"></script><script>
    function imgError(img){
        if (typeof img.hasReplaceSrc != 'undefined'){
            var refer = $('div.author a:last').attr('href');
            img.src = '/imgr?src=' + encodeURIComponent(img.src) + '&r=' + encodeURIComponent(refer);
        } else {
            var urlPattern = /(http|ftp|https):\/\/[\w-]+(\.[\w-]+)+([\w.,@?^=%&amp;:\/~+#-]*[\w@?^=%&amp;\/~+#-])?/;
            for (var i=0;i<img.attributes.length;i++){
                var attrName = img.attributes[i].nodeName;
                var attrVal = img.attributes[i].nodeValue;
                if(attrName.toLowerCase() != 'src' && urlPattern.test(attrVal)){
                    img.src = attrVal;
                    img.hasReplaceSrc=true;
                    break;
                }
            }
        }
        return true;
    }
</script>
<p>
 近期优化了一个
 <a rel="nofollow external" href="http://litao1990.tumblr.com/post/131267797733/hello-spark">
  spark流量统计的程序
 </a>
 ，此程序跑5分钟小数据量日志不到5分钟，但相同的程序跑一天大数据量日志各种失败。经优化，使用160 vcores + 480G memory，一天的日志可在2.5小时内跑完，下面对一些优化的思路方法进行梳理。
</p>
<hr>
<h2>
 优化的目标
</h2>
<ol>
 <li>
  保证大数据量下任务运行成功
 </li>
 <li>
  降低资源消耗
 </li>
 <li>
  提高计算性能
 </li>
</ol>
<p>
 三个目标优先级依次递减，首要解决的是程序能够跑通大数据量，资源性能尽量进行优化。
</p>
<hr>
<h2>
 基础优化
</h2>
<p>
 这部分主要对程序进行优化，主要考虑stage、cache、partition等方面。
</p>
<h3>
 Stage
</h3>
<p>
 在进行shuffle操作时，如reduceByKey、groupByKey，会划分新的stage。同一个stage内部使用pipe line进行执行，效率较高；stage之间进行shuffle，效率较低。故大数据量下，应进行代码结构优化，尽量减少shuffle操作。
</p>
<h3>
 Cache
</h3>
<p>
 本例中，首先计算出一个baseRDD，然后对其进行cache，后续启动三个子任务基于cache进行后续计算。
</p>
<p>
 对于5分钟小数据量，采用StorageLevel.MEMORY_ONLY，而对于大数据下我们直接采用了StorageLevel.DISK_ONLY。DISK_ONLY_2相较DISK_ONLY具有2备份，cache的稳定性更高，但同时开销更大，cache除了在executor本地进行存储外，还需走网络传输至其他节点。后续我们的优化，会保证executor的稳定性，故没有必要采用DISK_ONLY_2。实时上，如果优化的不好，我们发现executor也会大面积挂掉，这时候即便DISK_ONLY_2，也是然并卵，所以保证executor的稳定性才是保证cache稳定性的关键。
</p>
<p>
 cache是lazy执行的，这点很容易犯错，例如：
</p>
<pre class="prettyprint prettyprinted"><code class="prettyprint"><span class="pln">val raw </span><span class="pun">=</span><span class="pln"> sc</span><span class="pun">.</span><span class="pln">textFile</span><span class="pun">(</span><span class="pln">file</span><span class="pun">)</span><span class="pln">
val baseRDD </span><span class="pun">=</span><span class="pln"> raw</span><span class="pun">.</span><span class="pln">map</span><span class="pun">(...).</span><span class="pln">filter</span><span class="pun">(...)</span><span class="pln">
baseRDD</span><span class="pun">.</span><span class="pln">cache</span><span class="pun">()</span><span class="pln">
val threadList </span><span class="pun">=</span><span class="pln"> </span><span class="kwd">new</span><span class="pln"> </span><span class="typ">Array</span><span class="pun">(</span><span class="pln">
  </span><span class="kwd">new</span><span class="pln"> </span><span class="typ">Thread</span><span class="pun">(</span><span class="kwd">new</span><span class="pln"> </span><span class="typ">SubTaskThead1</span><span class="pun">(</span><span class="pln">baseRDD</span><span class="pun">)),</span><span class="pln">
  </span><span class="kwd">new</span><span class="pln"> </span><span class="typ">Thread</span><span class="pun">(</span><span class="kwd">new</span><span class="pln"> </span><span class="typ">SubTaskThead2</span><span class="pun">(</span><span class="pln">baseRDD</span><span class="pun">)),</span><span class="pln">
  </span><span class="kwd">new</span><span class="pln"> </span><span class="typ">Thread</span><span class="pun">(</span><span class="kwd">new</span><span class="pln"> </span><span class="typ">SubTaskThead3</span><span class="pun">(</span><span class="pln">baseRDD</span><span class="pun">))</span><span class="pln">
</span><span class="pun">)</span><span class="pln">
threadList</span><span class="pun">.</span><span class="pln">map</span><span class="pun">(</span><span class="pln">_</span><span class="pun">.</span><span class="pln">start</span><span class="pun">())</span><span class="pln">
threadList</span><span class="pun">.</span><span class="pln">map</span><span class="pun">(</span><span class="pln">_</span><span class="pun">.</span><span class="pln">join</span><span class="pun">())</span></code></pre>
<p>
 这个例子在三个子线程开始并行执行的时候，baseRDD由于lazy执行，还没被cache，这时候三个线程会同时进行baseRDD的计算，cache的功能形同虚设。可以在baseRDD.cache()后增加baseRDD.count()，显式的触发cache，当然count()是一个action，本身会触发一个job。
</p>
<p>
 再举一个错误的例子：
</p>
<pre class="prettyprint prettyprinted"><code class="prettyprint"><span class="pln">val raw </span><span class="pun">=</span><span class="pln"> sc</span><span class="pun">.</span><span class="pln">textFile</span><span class="pun">(</span><span class="pln">file</span><span class="pun">)</span><span class="pln">
val pvLog </span><span class="pun">=</span><span class="pln"> raw</span><span class="pun">.</span><span class="pln">filter</span><span class="pun">(</span><span class="pln">isPV</span><span class="pun">(</span><span class="pln">_</span><span class="pun">))</span><span class="pln">
val clLog </span><span class="pun">=</span><span class="pln"> raw</span><span class="pun">.</span><span class="pln">filter</span><span class="pun">(</span><span class="pln">isCL</span><span class="pun">(</span><span class="pln">_</span><span class="pun">))</span><span class="pln">
val baseRDD </span><span class="pun">=</span><span class="pln"> pvLog</span><span class="pun">.</span><span class="kwd">union</span><span class="pun">(</span><span class="pln">clLog</span><span class="pun">)</span><span class="pln">
val baseRDD</span><span class="pun">.</span><span class="pln">count</span><span class="pun">()</span></code></pre>
<p>
 由于textFile()也是lazy执行的，故本例会进行两次相同的hdfs文件的读取，效率较差。解决办法，是对pvLog和clLog共同的父RDD进行cache。
</p>
<h3>
 Partition
</h3>
<p>
 一个stage由若干partition并行执行，partition数是一个很重要的优化点。
</p>
<p>
 本例中，一天的日志由6000个小文件组成，加上后续复杂的统计操作，某个stage的parition数达到了100w。parition过多会有很多问题，比如所有task返回给driver的MapStatus都已经很大了，超过spark.driver.maxResultSize（默认1G），导致driver挂掉。虽然spark启动task的速度很快，但是每个task执行的计算量太少，有一半多的时间都在进行task序列化，造成了浪费，另外shuffle过程的网络消耗也会增加。
</p>
<p>
 对于reduceByKey()，如果不加参数，生成的rdd与父rdd的parition数相同，否则与参数相同。还可以使用coalesce()和repartition()降低parition数。例如，本例中由于有6000个小文件，导致baseRDD有6000个parition，可以使用coalesce()降低parition数，这样parition数会减少，每个task会读取多个小文件。
</p>
<pre class="prettyprint prettyprinted"><code class="prettyprint"><span class="pln">val raw </span><span class="pun">=</span><span class="pln"> sc</span><span class="pun">.</span><span class="pln">textFile</span><span class="pun">(</span><span class="pln">file</span><span class="pun">).</span><span class="pln">coalesce</span><span class="pun">(</span><span class="lit">300</span><span class="pun">)</span><span class="pln">
val baseRDD </span><span class="pun">=</span><span class="pln"> raw</span><span class="pun">.</span><span class="pln">map</span><span class="pun">(...).</span><span class="pln">filter</span><span class="pun">(...)</span><span class="pln">
baseRDD</span><span class="pun">.</span><span class="pln">cache</span><span class="pun">()</span></code></pre>
<p>
 那么对于每个stage设置多大的partition数合适那？当然不同的程度的复杂度不同，这个数值需要不断进行调试，本例中经测试保证每个parition的输入数据量在1G以内即可，如果parition数过少，每个parition读入的数据量变大，会增加内存的压力。例如，我们的某一个stage的ShuffleRead达到了3T，我设置parition数为6000，平均每个parition读取500M数据。
</p>
<pre class="prettyprint prettyprinted"><code class="prettyprint"><span class="pln">val bigRDD </span><span class="pun">=</span><span class="pln"> </span><span class="pun">...</span><span class="pln">
bigRDD</span><span class="pun">.</span><span class="pln">coalesce</span><span class="pun">(</span><span class="lit">6000</span><span class="pun">).</span><span class="pln">reduceBy</span><span class="pun">(...)</span></code></pre>
<p>
 最后，一般我们的原始日志很大，但是计算结果很小，在saveAsTextFile前，可以减少结果rdd的parition数目，这样会计算hdfs上的结果文件数，降低小文件数会降低hdfs namenode的压力，也会减少最后我们收集结果文件的时间。
</p>
<pre class="prettyprint prettyprinted"><code class="prettyprint"><span class="pln">val resultRDD </span><span class="pun">=</span><span class="pln"> </span><span class="pun">...</span><span class="pln">
resultRDD</span><span class="pun">.</span><span class="pln">repartition</span><span class="pun">(</span><span class="lit">1</span><span class="pun">).</span><span class="pln">saveAsTextFile</span><span class="pun">(</span><span class="pln">output</span><span class="pun">)</span></code></pre>
<p>
 这里使用repartition()不使用coalesce()，是为了不降低resultRDD计算的并发量，通过再做一次shuffle将结果进行汇总。
</p>
<hr>
<h2>
 资源优化
</h2>
<p>
 在搜狗我们的spark程序跑在yarn集群上，我们应保证我们的程序有一个稳定高效的集群环境。
</p>
<h3>
 设置合适的资源参数
</h3>
<p>
 一些常用的参数设置如下：
</p>
<pre class="prettyprint prettyprinted"><code class="prettyprint"><span class="pun">--</span><span class="pln">queue</span><span class="pun">：集群队列</span><span class="pln">
</span><span class="pun">--</span><span class="pln">num</span><span class="pun">-</span><span class="pln">executors</span><span class="pun">：</span><span class="pln">executor</span><span class="pun">数量，默认</span><span class="lit">2</span><span class="pln">
</span><span class="pun">--</span><span class="pln">executor</span><span class="pun">-</span><span class="pln">memory</span><span class="pun">：</span><span class="pln">executor</span><span class="pun">内存，默认</span><span class="lit">512M</span><span class="pln">
</span><span class="pun">--</span><span class="pln">executor</span><span class="pun">-</span><span class="pln">cores</span><span class="pun">：每个</span><span class="pln">executor</span><span class="pun">的并发数，默认</span><span class="lit">1</span></code></pre>
<p>
 executor的数量可以根据任务的并发量进行估算，例如我有1000个任务，每个任务耗时1分钟，若10个并发则耗时100分钟，100个并发耗时10分钟，根据自己对并发需求进行调整即可。默认每个executor内有一个并发执行任务，一般够用，也可适当增加，当然内存的使用也会有所增加。
</p>
<p>
 对于yarn-client模式，整个application所申请的资源为：
</p>
<pre class="prettyprint prettyprinted"><code class="prettyprint"><span class="pln">total vores </span><span class="pun">=</span><span class="pln"> executor</span><span class="pun">-</span><span class="pln">cores </span><span class="pun">*</span><span class="pln"> num</span><span class="pun">-</span><span class="pln">executors </span><span class="pun">+</span><span class="pln"> spark</span><span class="pun">.</span><span class="pln">yarn</span><span class="pun">.</span><span class="pln">am</span><span class="pun">.</span><span class="pln">cores
total memory</span><span class="pun">=</span><span class="pln"> </span><span class="pun">(</span><span class="pln">executor</span><span class="pun">-</span><span class="pln">memory </span><span class="pun">+</span><span class="pln"> spark</span><span class="pun">.</span><span class="pln">yarn</span><span class="pun">.</span><span class="pln">executor</span><span class="pun">.</span><span class="pln">memoryOverhead</span><span class="pun">)</span><span class="pln"> </span><span class="pun">*</span><span class="pln"> num</span><span class="pun">-</span><span class="pln">executors </span><span class="pun">+</span><span class="pln"> </span><span class="pun">(</span><span class="pln">spark</span><span class="pun">.</span><span class="pln">yarn</span><span class="pun">.</span><span class="pln">am</span><span class="pun">.</span><span class="pln">memory </span><span class="pun">+</span><span class="pln"> spark</span><span class="pun">.</span><span class="pln">yarn</span><span class="pun">.</span><span class="pln">am</span><span class="pun">.</span><span class="pln">memoryOverhead</span><span class="pun">)</span></code></pre>
<p>
 当申请的资源超出所指定的队列的min cores和min memory时，executor就有被yarn kill掉的风险。而spark的每个stage是有状态的，如果被kill掉，对性能影响比较大。例如，本例中的baseRDD被cache，如果某个executor被kill掉，会导致其上的cache的parition失效，需要重新计算，对性能影响极大。
</p>
<p>
 这里还有一点需要注意，executor-memory设置的是executor jvm启动的最大堆内存，java内存除了堆内存外，还有栈内存、堆外内存等，所以spark使用spark.yarn.executor.memoryOverhead对非堆内存进行限制，也就是说executor-memory + spark.yarn.executor.memoryOverhead是所能使用的内存的上线，如果超过此上线，就会被yarn kill掉。本次优化，堆外内存的优化起到了至关重要的作用，我们后续会看到。
</p>
<p>
 spark.yarn.executor.memoryOverhead默认是executor-memory * 0.1，最小是384M。比如，我们的executor-memory设置为1G，spark.yarn.executor.memoryOverhead是默认的384M，则我们向yarn申请使用的最大内存为1408M，但由于yarn的限制为倍数（不知道是不是只是我们的集群是这样），实际上yarn运行我们运行的最大内存为2G。这样感觉浪费申请的内存，申请的堆内存为1G，实际上却给我们分配了2G，如果对spark.yarn.executor.memoryOverhead要求不高的话，可以对executor-memory再精细化，比如申请executor-memory为640M，加上最小384M的spark.yarn.executor.memoryOverhead，正好一共是1G。
</p>
<p>
 除了启动executor外，spark还会启动一个am，可以使用spark.yarn.am.memory设置am的内存大小，默认是512M，spark.yarn.am.memoryOverhead默认也是最小384M。有时am会出现OOM的情况，可以适当调大spark.yarn.am.memory。
</p>
<p>
 executor默认的永久代内存是64K，可以看到永久代使用率长时间为99%，通过设置spark.executor.extraJavaOptions适当增大永久代内存，例如：–conf spark.executor.extraJavaOptions=“-XX:MaxPermSize=64m”
</p>
<p>
 driver端在yarn-client模式下运行在本地，也可以对相关参数进行配置，如–driver-memory等。
</p>
<h3>
 查看日志
</h3>
<p>
 executor的stdout、stderr日志在集群本地，当出问题时，可以到相应的节点查询，当然从web ui上也可以直接看到。
</p>
<p>
 executor除了stdout、stderr日志，我们可以把gc日志打印出来，便于我们对jvm的内存和gc进行调试。
</p>
<pre class="prettyprint prettyprinted"><code class="prettyprint"><span class="pun">--</span><span class="pln">conf spark</span><span class="pun">.</span><span class="pln">executor</span><span class="pun">.</span><span class="pln">extraJavaOptions</span><span class="pun">=</span><span class="str">"-XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime -XX:+PrintHeapAtGC -XX:+PrintGCApplicationConcurrentTime -Xloggc:gc.log"</span></code></pre>
<p>
 除了executor的日志，nodemanager的日志也会给我们一些帮助，比如因为超出内存上限被kill、资源抢占被kill等原因都能看到。
</p>
<p>
 除此之外，spark am的日志也会给我们一些帮助，从yarn的application页面可以直接看到am所在节点和log链接。
</p>
<h3>
 复杂的集群环境
</h3>
<p>
 我们的yarn集群节点上上跑着mapreduce、hive、pig、tez、spark等各类任务，除了内存有所限制外，CPU、带宽、磁盘IO等都没有限制（当然，这么做也是为了提高集群的硬件利用率），加上集群整体业务较多负载较高，使得spark的执行环境十分恶劣。常见的一些由于集群环境，导致spark程序失败或者性能下降的情况有：
</p>
<ul>
 <li>
  节点挂掉，导致此节点上的spark executor挂掉
 </li>
 <li>
  节点OOM，把节点上的spark executor kill掉
 </li>
 <li>
  CPU使用过高，导致spark程序执行过慢
 </li>
 <li>
  磁盘目录满，导致spark写本地磁盘失败
 </li>
 <li>
  磁盘IO过高，导致spark写本地磁盘失败
 </li>
 <li>
  HDFS挂掉，hdfs相关操作失败
 </li>
</ul>
<hr>
<h2>
 内存/GC优化
</h2>
<p>
 经过上述优化，我们的程序的稳定性有所提升，但是让我们完全跑通的最后一根救命稻草是内存、GC相关的优化。
</p>
<h3>
 Direct Memory
</h3>
<p>
 我们使用的spark版本是1.5.2（更准确的说是1.5.3-shapshot），shuffle过程中block的传输使用netty（spark.shuffle.blockTransferService）。基于netty的shuffle，使用direct memory存进行buffer（spark.shuffle.io.preferDirectBufs），所以在大数据量shuffle时，堆外内存使用较多。当然，也可以使用传统的nio方式处理shuffle，但是此方式在spark 1.5版本设置为deprecated，并将会在1.6版本彻底移除，所以我最终还是采用了netty的shuffle。
</p>
<p>
 jvm关于堆外内存的配置相对较少，通过-XX:MaxDirectMemorySize可以指定最大的direct memory。默认如果不设置，则与最大堆内存相同。
</p>
<p>
 Direct Memory是受GC控制的，例如ByteBuffer bb = ByteBuffer.allocateDirect(1024)，这段代码的执行会在堆外占用1k的内存，Java堆内只会占用一个对象的指针引用的大小，堆外的这1k的空间只有当bb对象被回收时，才会被回收，这里会发现一个明显的不对称现象，就是堆外可能占用了很多，而堆内没占用多少，导致还没触发GC。加上-XX:MaxDirectMemorySize这个大小限制后，那么只要Direct Memory使用到达了这个大小，就会强制触发GC，这个大小如果设置的不够用，那么在日志中会看到java.lang.OutOfMemoryError: Direct buffer memory。
</p>
<p>
 例如，在我们的例子中，发现堆外内存飙升的比较快，很容易被yarn kill掉，所以应适当调小-XX:MaxDirectMemorySize（也不能过小，否则会报Direct buffer memory异常）。当然你也可以调大spark.yarn.executor.memoryOverhead，加大yarn对我们使用内存的宽容度，但是这样比较浪费资源了。
</p>
<h3>
 GC优化
</h3>
<p>
 GC优化前，最好是把gc日志打出来，便于我们进行调试。
</p>
<pre class="prettyprint prettyprinted"><code class="prettyprint"><span class="pun">--</span><span class="pln">conf spark</span><span class="pun">.</span><span class="pln">executor</span><span class="pun">.</span><span class="pln">extraJavaOptions</span><span class="pun">=</span><span class="str">"-XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime -XX:+PrintHeapAtGC -XX:+PrintGCApplicationConcurrentTime -Xloggc:gc.log"</span></code></pre>
<p>
 通过看gc日志，我们发现一个case，特定时间段内，堆内存其实很闲，堆内存使用率也就5%左右，长时间不进行父gc，导致Direct Memory一直不进行回收，一直在飙升。所以，我们的目标是让父gc更频繁些，多触发一些Direct Memory回收。
</p>
<p>
 第一，可以减少整个堆内存的大小，当然也不能太小，否则堆内存也会报OOM。这里，我配置了1G的最大堆内存。
</p>
<p>
 第二，可以让年轻代的对象尽快进入年老代，增加年老代的内存。这里我使用了-Xmn100m，将年轻代大小设置为100M。另外，年轻代的对象默认会在young gc 15次后进入年老代，这会造成年轻代使用率比较大，young gc比较多，但是年老代使用率低，父gc比较少，通过配置-XX:MaxTenuringThreshold=1，年轻代的对象经过一次young gc后就进入年老代，加快年老代父gc的频率。
</p>
<p>
 第三，可以让年老代更频繁的进行父gc。一般年老代gc策略我们主要有-XX:+UseParallelOldGC和-XX:+UseConcMarkSweepGC这两种，ParallelOldGC吞吐率较大，ConcMarkSweepGC延迟较低。我们希望父gc频繁些，对吞吐率要求较低，而且ConcMarkSweepGC可以设置-XX:CMSInitiatingOccupancyFraction，即年老代内存使用率达到什么比例时触发CMS。我们决定使用CMS，并设置-XX:CMSInitiatingOccupancyFraction=10，即年老代使用率10%时触发父gc。
</p>
<p>
 通过对GC策略的配置，我们发现父gc进行的频率加快了，带来好处就是Direct Memory能够尽快进行回收，当然也有坏处，就是gc时间增加了，cpu使用率也有所增加。
</p>
<p>
 最终我们对executor的配置如下：
</p>
<pre class="prettyprint prettyprinted"><code class="prettyprint"><span class="pun">--</span><span class="pln">executor</span><span class="pun">-</span><span class="pln">memory </span><span class="lit">1G</span><span class="pln"> </span><span class="pun">--</span><span class="pln">num</span><span class="pun">-</span><span class="pln">executors </span><span class="lit">160</span><span class="pln"> </span><span class="pun">--</span><span class="pln">executor</span><span class="pun">-</span><span class="pln">cores </span><span class="lit">1</span><span class="pln"> </span><span class="pun">--</span><span class="pln">conf spark</span><span class="pun">.</span><span class="pln">yarn</span><span class="pun">.</span><span class="pln">executor</span><span class="pun">.</span><span class="pln">memoryOverhead</span><span class="pun">=</span><span class="lit">2048</span><span class="pln"> </span><span class="pun">--</span><span class="pln">conf spark</span><span class="pun">.</span><span class="pln">executor</span><span class="pun">.</span><span class="pln">extraJavaOptions</span><span class="pun">=</span><span class="str">"-XX:MaxPermSize=64m -XX:+CMSClassUnloadingEnabled -XX:MaxDirectMemorySize=1536m -Xmn100m -XX:MaxTenuringThreshold=1 -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:+UseCMSCompactAtFullCollection -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=10 -XX:+UseCompressedOops -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime -XX:+PrintHeapAtGC -XX:+PrintGCApplicationConcurrentTime -Xloggc:gc.log -XX:+HeapDumpOnOutOfMemoryError"</span></code></pre>
<hr>
<h2>
 总结
</h2>
<p>
 通过对Stage/Cache/Partition、资源、内存/GC的优化，我们的spark程序最终能够在160 vcores + 480G memory资源下，使用2.5小时跑通一天的日志。
</p>
<p>
 对于程序优化，我认为应本着如下几点进行：
</p>
<ol>
 <li>
  通过监控CPU、内存、网络、IO、GC、应用指标等数据，切实找到系统的瓶颈点。
 </li>
 <li>
  统筹全局，制定相应的解决方案，解决问题的思路是否清晰准确很重要，另外切勿『头疼医头，脚疼医脚』，应总体考虑把握。
 </li>
 <li>
  了解一些技术的背景知识，对于每次优化尽量做得彻底些，多进行总结。
 </li>
</ol>
<div class="like">
    <a href="javascript:void(0)" class="assertLogin" rel="nofollow" target="_self">点赞</a>
</div>
<div class="tags">
<a class="tag" href="http://ju.outofmemory.cn/tag/spark/">spark</a>

<a class="tag" href="http://ju.outofmemory.cn/tag/gc/">gc</a>

</div>

<div class="author">
    <span class="name">作者：<a href="http://ju.outofmemory.cn/feed/2894/" title="Tao&#39;s Blog">Tao's Blog</a></span>
    <div class="authorAvatar">
        <a href="http://ju.outofmemory.cn/feed/2894/">
            <img width="128" align="center" valign="absmiddle" src="./Spark性能优化总结 - 为程序员服务_files/2894.png" alt="Tao&#39;s Blog">
        </a>
    </div>
    <div class="small">
        On The Way
    </div>
    <div class="small">原文地址：<a rel="nofollow external" target="_blank" href="http://guaver.info/post/133730250338">Spark性能优化总结</a>, 感谢原作者分享。</div>
</div>

<div class="pn">
    <span class="next"><mark>→</mark><a href="http://ju.outofmemory.cn/entry/237301">Spark-JobServer "pemgen space"异常分析</a></span>
    <span class="pre"><mark>←</mark><a href="http://ju.outofmemory.cn/entry/237299">(via https://www.youtube.com/watch?v=l5IrndowT6w)</a></span>
</div>

<div class="comments">
<a name="comments"></a>
</div>


<div class="newComment"><a name="newComment"></a>
<h3>发表评论</h3>
<form action="http://ju.outofmemory.cn/entry/comment/add" method="POST">
    <input type="hidden" name="targetId" value="237300">
    <input type="hidden" name="title" value="回复:Spark性能优化总结">
    <input type="hidden" name="replyId">
    <textarea name="content" cols="100" rows="6" class="mdInput" style="width:98%"></textarea>
    <p>
        <button type="button" id="btnComment">发表评论</button><span id="commentTip"></span>
    </p>
</form>
</div>




</div>
<div class="sidebar">
    <div class="similar entry">
    <span class="title">您可能感兴趣的博客</span>
    <div><ul class="similarEntries">
    <li><span class="meta"><a href="http://ju.outofmemory.cn/feed/2894/" title="博主">博主</a> 发表 <span class="time" title="2015-11-22 16:25:20">3月前</span></span>
<a href="./Spark性能优化总结 - 为程序员服务_files/Spark性能优化总结 - 为程序员服务.html" class="codeTitle">Spark性能优化总结</a>
</li>
    <li><span class="meta"><a href="http://ju.outofmemory.cn/feed/205/" title="hugozhu">hugozhu</a> 发表 <span class="time" title="2013-04-18 12:01:04">2年前</span></span>
<a href="http://ju.outofmemory.cn/entry/21052" class="codeTitle">内存屏障</a>
</li>
    <li><span class="meta"><a href="http://ju.outofmemory.cn/feed/205/" title="juemeng">juemeng</a> 发表 <span class="time" title="2013-10-10 15:21:53">2年前</span></span>
<a href="http://ju.outofmemory.cn/entry/52178" class="codeTitle">JVM 内部运行线程介绍</a>
</li>
    <li><span class="meta"><a href="http://ju.outofmemory.cn/feed/123/" title="范琦琦">范琦琦</a> 发表 <span class="time" title="2014-03-31 16:00:53">1年前</span></span>
<a href="http://ju.outofmemory.cn/entry/69343" class="codeTitle">如何估算内存消耗</a>
</li>
    <li><span class="meta"><a href="http://ju.outofmemory.cn/feed/1358/" title="ticmy">ticmy</a> 发表 <span class="time" title="2013-05-17 12:02:05">2年前</span></span>
<a href="http://ju.outofmemory.cn/entry/74697" class="codeTitle">[读书笔记]《Java Performance》GC（1）</a>
</li>
    <li><span class="meta"><a href="http://ju.outofmemory.cn/feed/1561/" title="">博主</a> 发表 <span class="time" title="2014-08-02 00:00:00">1年前</span></span>
<a href="http://ju.outofmemory.cn/entry/89090" class="codeTitle">Spark - 分布式计算无痛上手指南</a>
</li>
    <li><span class="meta"><a href="http://ju.outofmemory.cn/feed/1667/" title="debugo">debugo</a> 发表 <span class="time" title="2014-09-07 08:49:33">1年前</span></span>
<a href="http://ju.outofmemory.cn/entry/96016" class="codeTitle">Spark中的编程模型</a>
</li>
    <li><span class="meta"><a href="http://ju.outofmemory.cn/feed/1777/" title="bandit">bandit</a> 发表 <span class="time" title="2014-09-11 07:52:23">1年前</span></span>
<a href="http://ju.outofmemory.cn/entry/101514" class="codeTitle">[转载]Linux下取代top的进程管理工具 htop</a>
</li>
    <li><span class="meta"><a href="http://ju.outofmemory.cn/feed/1827/" title="博主">博主</a> 发表 <span class="time" title="2015-01-06 09:34:06">1年前</span></span>
<a href="http://ju.outofmemory.cn/entry/109182" class="codeTitle">Spark Streaming 集成 Kafka 总结</a>
</li>
    <li><span class="meta"><a href="http://ju.outofmemory.cn/feed/2065/" title="">博主</a> 发表 <span class="time" title="2014-12-25 00:00:00">1年前</span></span>
<a href="http://ju.outofmemory.cn/entry/115327" class="codeTitle">Spark Zeromq</a>
</li>
    <li><span class="meta"><a href="http://ju.outofmemory.cn/feed/2318/" title="">博主</a> 发表 <span class="time" title="2015-02-03 16:00:00">1年前</span></span>
<a href="http://ju.outofmemory.cn/entry/128877" class="codeTitle">如何在CDH5上运行Spark应用</a>
</li>
    <li><span class="meta"><a href="http://ju.outofmemory.cn/feed/2318/" title="博主">博主</a> 发表 <span class="time" title="2015-04-16 16:00:00">10月前</span></span>
<a href="http://ju.outofmemory.cn/entry/132793" class="codeTitle">Spark MLlib中的协同过滤</a>
</li>
</ul>
</div>
</div>




    <div>&nbsp;</div>
    <div class="similar code">
    <span class="title">您可能感兴趣的代码</span>
    <div><ul class="similarCodes">
    <li><span class="time" title="2012-11-16 22:32:49">3年前</span><a href="http://outofmemory.cn/code-snippet/628/python-webpy-display-process-suoyou-type-object-involve-de-neicundaxiao">python webpy中显示进程中的所有类型对象占用的内存大小</a> by <a href="http://outofmemory.cn/user/7">金背二郎</a>
</li>
    <li><span class="time" title="2014-09-02 19:54:41">1年前</span><a href="http://outofmemory.cn/code-snippet/15849/HTML-Spark-view-engine-usage-instance">HTML： Spark view引擎使用举例</a> by <a href="http://outofmemory.cn/user/75">huwei</a>
</li>
    <li><span class="time" title="2014-11-08 09:38:19">1年前</span><a href="http://outofmemory.cn/code-snippet/34336/Java-GC">Java中的垃圾回收机制</a> by <a href="http://outofmemory.cn/user/96">sdcool</a>
</li>
    <li><span class="time" title="2014-11-16 11:35:26">1年前</span><a href="http://outofmemory.cn/code-snippet/34715/Java-recover">Java中的垃圾回收机制</a> by <a href="http://outofmemory.cn/user/96">sdcool</a>
</li>
    <li><span class="time" title="2016-02-22 21:45:07">16小时前</span><a href="http://outofmemory.cn/code-snippet/39376/Get-the-expaned-path-through-expand-path">Get the expaned path through expand_path</a> by <a href="http://outofmemory.cn/user/57">zetaliang</a>
</li>
    <li><span class="time" title="2016-02-22 20:29:27">18小时前</span><a href="http://outofmemory.cn/code-snippet/39375/Create-set-with-constant-values">Create set with constant values</a> by <a href="http://outofmemory.cn/user/69">Loli控</a>
</li>
    <li><span class="time" title="2016-02-22 18:45:04">19小时前</span><a href="http://outofmemory.cn/code-snippet/39374/Finds-all-files-modified-more-recently-than-a-certain-number-of-seconds-ago">Finds all files modified more recently than a certain number of seconds ago.</a> by <a href="http://outofmemory.cn/user/81">永明</a>
</li>
    <li><span class="time" title="2016-02-22 18:35:56">19小时前</span><a href="http://outofmemory.cn/code-snippet/39373/Android-get-IP-address">Android 获取 IP 地址</a> by <a href="http://outofmemory.cn/user/78">李兰军</a>
</li>
    <li><span class="time" title="2016-02-22 17:20:17">21小时前</span><a href="http://outofmemory.cn/code-snippet/39372/Being-a-lowercase-letter">Being a lowercase letter</a> by <a href="http://outofmemory.cn/user/129">digua</a>
</li>
    <li><span class="time" title="2016-02-22 16:20:28">22小时前</span><a href="http://outofmemory.cn/code-snippet/39371/hexadecimal-integers">hexadecimal integers</a> by <a href="http://outofmemory.cn/user/45">LeoSun</a>
</li>
    <li><span class="time" title="2016-02-22 14:16:08">1天前</span><a href="http://outofmemory.cn/code-snippet/39370/Parse-a-mp3-file">Parse a mp3 file</a> by <a href="http://outofmemory.cn/user/45">LeoSun</a>
</li>
    <li><span class="time" title="2016-02-22 12:53:38">1天前</span><a href="http://outofmemory.cn/code-snippet/39369/java-util-NavigableMap-class-example-code">java.util.NavigableMap 类示例代码</a> by <a href="http://outofmemory.cn/user/147">冬夜微风</a>
</li>
</ul>
</div>
</div>



    <div>&nbsp;</div>
</div>


</div>
<script src="./Spark性能优化总结 - 为程序员服务_files/jquery-1.11.3.min.js"></script>
<script>var isMobile= $('.sidebar').css('clear') == 'both';</script>
<script src="./Spark性能优化总结 - 为程序员服务_files/loginUser_v5" charset="utf-8"></script>
<script src="./Spark性能优化总结 - 为程序员服务_files/prettify.js" type="text/javascript"></script>
<script src="./Spark性能优化总结 - 为程序员服务_files/5.js"></script>
<script>
    var removeAD=true;
    var voteTargetType='entry';var voteTargetId =237300;
    var voting=false;
    function onGetVoteStatus(status){
        if(status.type != 0){
            voting=true;
            $('.like a').html('0赞');
        }
    }
    $('.like a').click(function(){
        if (!voting){
            voting = true;
            $.post("/"+voteTargetType+"/"+voteTargetId+"/vote", { type: '1'},
            function (response, textStatus){
                if(!response.success){
                    alert(response.message);
                } else {
                    $('.like a').html((response.upCount||1) + '赞');
                }
            }, "json");
        } else {
            $('.like a').html('已赞');
        }
    });
    $('pre,code').removeClass('prettyprint').addClass('prettyprint');
    prettyPrint();
    function displayPv(pv){
        $('.pv b').html(pv + '');
    }
    function resizeImg(o,maxWidth) {
        var img = $(o);
        if(img.width() > maxWidth) {
            var h = Math.round(maxWidth / img.width() * img.height());
            img.width(maxWidth).height(h);
        }
    }
    function resizeImgs(){
        var maxWidth = $('div.author').width();
        $('.content img').each(
            function(i,o){resizeImg(o,maxWidth);}
        );
        var tg = $('.tgBD');
        if(tg.width()>maxWidth){
            tg.width(maxWidth+'px').css({'text-align':'center','overflow':'hidden',border:'1px solid transparent','border-radius':'2px','-moz-border-radius':'2px'});
        }
    }
    $(resizeImgs);
    $(window).resize(resizeImgs);
</script>


<footer class="foot">
© 2015 <a href="http://outofmemory.cn/">内存溢出</a>
</footer>












<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-36036446-1', 'outofmemory.cn');
    ga('send', 'pageview');
    ga('set',  '&uid', window.loginUser.id); // 使用已登录的 user_id 来设置用户 ID。
</script>

<div class="bdtj"><script type="text/javascript">


var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?2051de3619785a7bff6213250ea9fbbd";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>
</div>
<script>
    function displayTG(k, h){
        var display = typeof removeAD != 'undefined' && !removeAD;
        if (!display) {
            return;
        }
        if(k == 'jukeTopLine'){
            $(h).insertBefore($('div.wrap'));
        }
    }
    if(parseInt($('.content').css('marginRight')) > 50){
        var contentHeight=$('.content').height();var sideHeight=$('.sidebar').height();
        if(contentHeight<sideHeight) $('.content').css({'minHeight':sideHeight+'px'});
    }
</script>


<div class="codeTools" style="left: 1222px; top: 4728.32px;"><div id="copyCode">复制代码</div><div id="saveCode">保存代码</div><div id="runCode" style="display: none;">试试效果</div></div><div style="position: absolute; left: 1228px; top: 4736px; width: 64px; height: 13px; z-index: 99;"><embed id="ZeroClipboardMovie_1" src="/static/clipboard/ZeroClipboard10.swf" loop="false" menu="false" quality="best" bgcolor="#ffffff" width="64" height="13" name="ZeroClipboardMovie_1" allowscriptaccess="always" allowfullscreen="false" type="application/x-shockwave-flash" pluginspage="http://www.macromedia.com/go/getflashplayer" flashvars="id=1&amp;width=64&amp;height=13" wmode="transparent"></div>

<script>window.__key__ = '17b32d4535037b3fe3e23ab2fee48cab';</script>
<script src="./Spark性能优化总结 - 为程序员服务_files/aes.js" type="text/javascript"></script>
<script>
$('form').submit(
        function(e){
            $('input[type="password"]').each(function(o){
                var oPwd = $(this);
                var pwd = oPwd.val();
                if (pwd){
                    var key = CryptoJS.enc.Latin1.parse(window.__key__.substring(0, 16));
                    var iv = CryptoJS.enc.Latin1.parse(window.__key__.substring(16));
                    //加密
                    var encrypted = CryptoJS.AES.encrypt(pwd, key, {iv:iv,mode:CryptoJS.mode.CBC,padding:CryptoJS.pad.ZeroPadding});
                    oPwd.val(encrypted.toString());
                }
            });
        }
);
</script></body></html>